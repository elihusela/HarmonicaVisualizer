# HarmonicaTabs Project - Claude Notes

## Project Overview
Generates animated harmonica tablature videos from input videos, tab files, and harmonica models. Creates visual animations that sync audio with harmonica tab notation.

## Current Workflow Issues
- **Manual MIDI intervention**: Code stops, requires manual MIDI fixing in Ableton, then restart
- **Cumbersome arguments**: Each new video requires many command-line arguments
- **Slow video generation**: Performance could be improved
- **No tests**: Makes refactoring risky and scary

## Main Goals
### 1. Split the Pipeline into Two Phases
- **Phase 1**: Generate MIDI file, then stop
- **Phase 2**: Take fixed MIDI file and generate final video
- **Testing mode**: Option to connect both phases for automated testing

### 2. Improve Developer Experience
- Simplify command-line interface
- Add configuration files or better argument handling
- Speed up video generation process

### 3. Add Testing
- Create test suite to enable confident refactoring
- Test individual components and full pipeline

### 4. Refactor Codebase
- Extract pipeline logic from main.py into proper classes
- Improve code organization and separation of concerns
- Better error handling and validation
- More maintainable and extensible architecture

## Current Technical Debt
- Single monolithic pipeline in `main.py`
- Hard-coded file paths and arguments
- No separation between MIDI generation and video creation
- Missing error handling and validation

## Next Steps
1. Analyze current pipeline structure
2. Design two-phase architecture
3. Add basic testing framework
4. Refactor main.py into separate phases
5. Improve CLI interface

## Development Notes
- Uses Poetry for dependency management
- Has pre-commit hooks configured
- Current entry point: `main.py` with 6+ arguments
- MIDI files stored in `fixed_midis/` directory

## Context7 MCP Server - Library Documentation
**IMPORTANT**: Always use the context7 MCP server when working with external libraries or when documentation is needed.

### When to Use Context7
- Need up-to-date API documentation for any library (moviepy, numpy, matplotlib, etc.)
- Working with unfamiliar library features or methods
- Need code examples for specific library functionality
- Debugging library-specific issues
- Verifying correct usage patterns before implementation

### How to Use
1. **First**: Call `resolve-library-id` to get the Context7-compatible library ID
2. **Then**: Call `get-library-docs` with the library ID and optional topic

### Examples
```python
# When working with moviepy video editing
# 1. Resolve: mcp__context7__resolve-library-id(libraryName="moviepy")
# 2. Get docs: mcp__context7__get-library-docs(context7CompatibleLibraryID="/Zulko/moviepy", topic="concatenate videos")

# When working with basic_pitch for MIDI generation
# 1. Resolve: mcp__context7__resolve-library-id(libraryName="basic-pitch")
# 2. Get docs: mcp__context7__get-library-docs(context7CompatibleLibraryID="/spotify/basic-pitch", topic="thresholds")

# When working with matplotlib for figure rendering
# 1. Resolve: mcp__context7__resolve-library-id(libraryName="matplotlib")
# 2. Get docs: mcp__context7__get-library-docs(context7CompatibleLibraryID="/matplotlib/matplotlib", topic="transparent background")
```

### Guidelines
- Always fetch docs BEFORE implementing new library features
- Use specific topics to get targeted documentation
- Verify API usage against latest docs (knowledge cutoff: Jan 2025)
- Especially important for: moviepy, basic_pitch, matplotlib, numpy, PIL

## Technical Architecture & Components

### Harmonica Note Mappings
- **Location**: `tab_converter/consts.py` â†’ `C_HARMONICA_MAPPING`
- **MIDI Range**: Notes 60-96 (C4 to C7) mapped to harmonica holes 1-10
- **Format**: Positive = blow notes, Negative = draw notes
- **Visual Mapping**: `image_converter/consts.py` â†’ hole coordinates for animation
- **Coverage**: 19 mapped notes, some holes like Draw 2 commented out

### Two-Phase Pipeline Architecture
```
Phase 1 (generate-midi): Video/Audio â†’ MIDI Generation
â”œâ”€â”€ AudioExtractor â†’ WAV extraction
â”œâ”€â”€ basic_pitch â†’ Raw MIDI (all notes)
â””â”€â”€ Output: temp/*_generated.mid for manual editing

Phase 2 (create-video): Fixed MIDI â†’ Harmonica Animation
â”œâ”€â”€ MIDI Loading â†’ Note events
â”œâ”€â”€ TabMapper â†’ Harmonica tabs (filtered by C_HARMONICA_MAPPING)
â”œâ”€â”€ TabMatcher â†’ Tab timing alignment
â””â”€â”€ Animator â†’ Final harmonica video
```

### Key Processing Components
1. **MIDI Processing**: `harmonica_pipeline/midi_generator.py`
   - Uses Spotify's basic_pitch AI model
   - Thresholds: onset=0.2, frame=0.2
   - Now supports WAV files directly

2. **Tab Conversion**: `tab_converter/tab_mapper.py`
   - Core mapping logic using `C_HARMONICA_MAPPING`
   - Filters out unmapped MIDI notes silently
   - Converts MIDI notes to harmonica hole numbers

3. **Animation**: `image_converter/animator.py`
   - Creates visual harmonica hole animations
   - Uses coordinate mappings for precise positioning

### Current Filtering Mechanisms
- **Mapping-based**: Only notes in `C_HARMONICA_MAPPING` processed
- **Pitch bend removal**: All MIDI pitch bends stripped
- **Range filtering**: Implicit through mapping dictionary (60-96)
- **Confidence thresholds**: basic_pitch onset/frame filtering

### Data Flow
```
Video/Audio â†’ AudioExtractor â†’ basic_pitch â†’ Raw MIDI â†’
Manual Edit â†’ Fixed MIDI â†’ TabMapper (C_HARMONICA_MAPPING filter) â†’
TabMatcher â†’ Animator â†’ Final Video
```

### Optimal MIDI Filtering Integration Points
1. **TabMapper.note_events_to_tabs()** (Recommended)
   - Location: `tab_converter/tab_mapper.py:18`
   - Current: `if event.pitch in self._mapping:`
   - Enhancement: Add range filtering before mapping check

2. **MIDI Loading Functions**
   - Add filtering during note event parsing
   - Configurable per harmonica model

## Recent Improvements
- âœ… WAV file support added to generate-midi command
- âœ… Two-phase CLI architecture implemented
- âœ… Separated MIDI generation from video creation
- âœ… **3-step audio processing flow implemented**
- âœ… **OOP architecture with AudioProcessor class**
- âœ… **Enhanced AudioExtractor with ffmpeg fallback**
- âœ… **Simplified workflow (auto-naming, WAV reuse)**
- âœ… HarmonicaTabs Claude Code agent created (harmonica-dev subagent)
- âœ… **Tab phrase animation bug fixed** (multiple pages now generated)
- âœ… **Selective generation options** (--only-tabs, --only-harmonica)
- âœ… **Text-based structure implementation** (.txt file page/line organization preserved)
- âœ… **Chronological MIDI timing** (left-to-right note lighting order fixed)
- âœ… **TabEntry constructor fixes** (confidence parameter added)
- âœ… **All 12 harmonica keys supported** (--key CLI flag with A, Ab, B, Bb, C, C#, D, E, Eb, F, F#, G)

## Latest Architecture (Sept 2024)

### ðŸŽµ **Simplified 2-Phase Workflow:**
```bash
# Phase 1: Video/Audio â†’ MIDI (auto-naming, WAV extraction)
python cli.py generate-midi JGNBLLS_C.m4v

# Fix MIDI in DAW â†’ save as fixed_midis/MySong_fixed.mid

# Phase 2: WAV â†’ Video (reuses extracted audio)
python cli.py create-video JGNBLLS_C.m4v JNGLBLLS.txt --key C

# With different harmonica keys:
python cli.py create-video AMEDI_Bb.m4v AMEDI.txt --key Bb
python cli.py create-video song.wav song.txt --key F#   # F-sharp harmonica
python cli.py create-video song.wav song.txt --key D    # D harmonica

# Selective Generation Options:
python cli.py create-video MySong.wav MySong.txt --only-tabs        # Only tab phrase animations
python cli.py create-video MySong.wav MySong.txt --only-harmonica   # Only harmonica animation
```

### ðŸ—ï¸ **OOP Audio Processing Architecture:**
```
utils/
â”œâ”€â”€ audio_extractor.py     # VideoExtractor â†’ WAV (MoviePy + ffmpeg fallback)
â”œâ”€â”€ audio_processor.py     # AudioProcessor class (kaki.sh logic)
â””â”€â”€ audio_processor.sh     # Original kaki.sh (documentation)
```

### ðŸŽ›ï¸ **Audio Processing Pipeline (kaki.sh integration):**
1. **Video â†’ WAV**: Extract with fallback (complex iPhone videos supported)
2. **WAV â†’ Processed**: Mono + 200-5000Hz filter + noise reduction + loudnorm
3. **Processed â†’ MIDI**: basic_pitch with optimized thresholds (0.4/0.3)
4. **WAV Reuse**: Auto-saved to video-files/ for Phase 2

### ðŸ“Š **Quality Results:**
- **Before processing**: 236 note events (noisy)
- **After kaki.sh processing**: 113 note events (52% noise reduction)
- **iPhone 16 Pro Max support**: HEVC, multiple audio streams handled

### ðŸŽ¯ **Key OOP Components:**
- **MidiGenerator**: 3-step pipeline orchestration
- **AudioExtractor**: Robust videoâ†’audio with fallbacks
- **AudioProcessor**: Configurable kaki.sh logic with presets
- **VideoCreator**: Phase 2 video generation with selective creation support

### ðŸŽ­ **Selective Generation Options (Latest Feature):**
New CLI options for targeted video creation:

```bash
# Create both animations (default behavior)
python cli.py create-video PMV.wav PMV.txt

# Create only tab phrase animations (skip harmonica)
python cli.py create-video PMV.m4v PMV.txt --only-tabs

# Create only harmonica animation (skip tab phrases)
python cli.py create-video PMV.m4v PMV.txt --only-harmonica

# Skip all tab generation (original option)
python cli.py create-video MySong.wav MySong.txt --no-produce-tabs

# Error: Cannot use both selective options
python cli.py create-video MySong.wav MySong.txt --only-tabs --only-harmonica
# âŒ Error: Cannot specify both --only-tabs and --only-harmonica
```

**Use Cases:**
- **Development**: Test individual components separately
- **Performance**: Skip slow animations when iterating
- **Debugging**: Isolate issues to specific animation types
- **Workflow**: Generate harmonica first, then tabs after review

---

## ðŸŽ¯ NEXT FEATURE: Full Tab Video Compositor

### **Feature Overview**
Create a **single continuous video** where tab pages appear/disappear in sync with the audio, with individual notes lighting up precisely as they play. This stitches together all tab pages into one video for easy Final Cut Pro compositing.

### **Current State**
- âœ… TabPhraseAnimator generates **separate** page videos (`page1_tabs.mov`, `page2_tabs.mov`, etc.)
- âœ… Each page video has notes lighting up in sync with timing
- âœ… Works great, but requires manual stitching in editing software

### **What We're Building**
**Output:** `MySong_full_tabs.mov` - One continuous video file where:
1. **Page-by-page display** (NOT scrolling)
2. **Pages appear/disappear** at exact times based on note timing
3. **Notes light up individually** within each visible page
4. **Transparent background** (for compositing on original video)
5. **Synced to audio duration** (precise timing)

### **Visual Behavior**
```
Timeline Example (song.wav = 30 seconds):
[0.0-0.1s]   Blank (transparent)
[0.1-10.2s]  Page 1 visible, notes glow as they play (first note at 0.1s, last at 10.1s)
[10.2-10.3s] Blank transition
[10.3-20.1s] Page 2 visible, notes glow as they play
[20.1-20.2s] Blank transition
[20.2-30.0s] Page 3 visible, notes glow as they play
```

### **Page Timing Logic**
Each page visibility window calculated from note timings:
- `page_start = first_note_time - 0.1s` (small padding before)
- `page_end = last_note_time + 0.1s` (small padding after)
- **Instant cut** between pages (no fade)
- **Blank (transparent) frames** during gaps

### **Requirements (Clarified)**
âœ… **Don't touch harmonica animation** - stays separate for manual Final Cut compositing
âœ… **Same rendering style** - reuse existing tab page rendering
âœ… **Transparent background** - for video overlay
âœ… **Same note glow effect** - as current TabPhraseAnimator
âœ… **Page always visible** - notes glow individually, page stays on screen
âœ… **Instant transitions** - no fade, just cut between pages

### **Architecture Decision**

#### **New Module:** `tab_phrase_animator/full_tab_video_compositor.py`

**Class:** `FullTabVideoCompositor`

**Approach: Reuse Existing Page Videos** (Option A - Recommended)
- Leverage already-generated page videos from `TabPhraseAnimator`
- Read `page1_tabs.mov`, `page2_tabs.mov`, etc.
- Calculate precise timing windows from note data
- Stitch videos with blank (transparent) frames in between
- Faster iteration, reuses existing work

**Alternative: Generate Fresh** (Option B - Cleaner but slower)
- Similar to TabPhraseAnimator but render all pages into ONE video
- More control but duplicate work

### **CLI Integration**

```bash
# Default: Generate individual pages + full video
python cli.py create-video BDAY.mov BDAY.txt

# Skip full video (only individual pages)
python cli.py create-video song.wav song.txt --no-full-tab-video

# Only full video (skip individual pages)
python cli.py create-video BLCKBRD.m4v BLCKBRD.txt --only-full-tab-video

# Existing flags still work
python cli.py create-video song.wav song.txt --only-tabs  # No harmonica, yes tabs
```

### **File Outputs**
```
outputs/
â”œâ”€â”€ MySong_harmonica.mov       (unchanged - harmonica hole animation)
â”œâ”€â”€ MySong_tabs.mov            (existing - individual tab pages stitched)
â””â”€â”€ MySong_full_tabs.mov       (NEW - continuous page-by-page video)
```

### **Implementation Steps**

#### **Phase 1: Core Compositor Class**
1. Create `tab_phrase_animator/full_tab_video_compositor.py`
2. Implement `FullTabVideoCompositor` class:
   - Constructor: takes page videos, note timing data, audio duration
   - `calculate_page_windows()` - determine when each page appears/disappears
   - `create_blank_frame()` - generate transparent frame
   - `stitch_videos()` - concatenate page videos with blank frames
   - `generate()` - main entry point, outputs full video

#### **Phase 2: VideoCreator Integration**
1. Add flag to `VideoCreatorConfig`: `produce_full_tab_video` (default: `True`)
2. Modify `VideoCreator.create()`:
   - After generating individual pages
   - If `produce_full_tab_video` enabled
   - Call `FullTabVideoCompositor.generate()`
3. Pass through all necessary data (page videos, timing, audio length)

#### **Phase 3: CLI Flags**
1. Add `--no-full-tab-video` flag to `cli.py`
2. Add `--only-full-tab-video` flag to `cli.py`
3. Update help text and documentation

#### **Phase 4: Testing**
1. Create `tests/tab_phrase_animator/test_full_tab_video_compositor.py`
2. Test timing calculations
3. Test video stitching logic
4. Integration test with real page videos

### **Technical Considerations**

**Video Library:** Use `moviepy` (already in dependencies)
```python
from moviepy.editor import VideoFileClip, concatenate_videoclips, ColorClip

# Read existing page videos
page1 = VideoFileClip("page1_tabs.mov")
page2 = VideoFileClip("page2_tabs.mov")

# Create blank (transparent) frames
blank = ColorClip(size=(1920, 1080), color=(0,0,0,0), duration=0.1)

# Concatenate with timing
final = concatenate_videoclips([blank, page1, blank, page2, ...])
```

**Timing Data Source:** Use existing `TabMatcher` output or MIDI timing

**Precision:** Use MIDI timing data (already accurate to milliseconds)

### **Success Criteria**
âœ… Single video file generated
âœ… Pages appear/disappear at correct times
âœ… Notes light up in sync with audio
âœ… Transparent background maintained
âœ… Total video duration matches audio duration
âœ… Instant cuts between pages (no fade)
âœ… CLI flags work as expected
âœ… Tests passing

### **Next Session: Start Here** ðŸš€
1. Create `tab_phrase_animator/full_tab_video_compositor.py`
2. Implement `FullTabVideoCompositor` class skeleton
3. Write timing calculation logic
4. Test with one song's page videos

---

## ðŸŽ¹ Harmonica Key Selection (--key flag) âœ… COMPLETED

### **Overview**
All 12 harmonica keys are fully supported via the `--key` CLI flag. The system automatically selects the correct:
- Harmonica model image (PNG)
- MIDI note mapping (pitch â†’ hole number)
- Hole coordinate mapping (for animation)

### **Supported Keys (12 total)**
| Key | Model Image | Notes |
|-----|-------------|-------|
| A   | A.png       | 19 MIDI notes |
| Ab  | Ab.png      | 19 MIDI notes |
| B   | b.png       | 19 MIDI notes |
| Bb  | Bb.png      | 19 MIDI notes |
| C   | c.png | 19 MIDI notes (default) |
| C#  | c#.png      | 19 MIDI notes |
| D   | D.png       | 19 MIDI notes |
| E   | E.png       | 19 MIDI notes |
| Eb  | Eb.png      | 19 MIDI notes |
| F   | F.png       | 19 MIDI notes |
| F#  | F#.png      | 19 MIDI notes |
| G   | G.png       | 19 MIDI notes |

### **CLI Usage**
```bash
# Default: Use C harmonica
python cli.py create-video song.wav song.txt

# Specify a key (case-insensitive)
python cli.py create-video song.wav song.txt --key G
python cli.py create-video song.wav song.txt --key Bb
python cli.py create-video song.wav song.txt --key F#
python cli.py create-video song.wav song.txt --key Ab

# Works with full pipeline too
python cli.py full song.mp4 song.txt --key D

# Key aliases work (F# = FS, C# = CS, etc.)
python cli.py create-video song.wav song.txt --key f#   # Same as --key FS
```

### **Key Features**
- âœ… **Case-insensitive**: `C`, `c`, `G`, `g` all work
- âœ… **Common aliases**: `F#` â†’ FS, `C#` â†’ CS, `Bb` â†’ BB, `Ab` â†’ AB, `Eb` â†’ EB
- âœ… **Auto-selection**: Model image, MIDI mapping, and hole coordinates selected automatically
- âœ… **Validation**: Clear error messages for unsupported keys
- âœ… **Override option**: Can still use `--harmonica-model` for custom images

### **Architecture**
```
harmonica_pipeline/
â”œâ”€â”€ harmonica_key_registry.py   # Central registry for all keys
â”‚   â”œâ”€â”€ HarmonicaKeyConfig      # Dataclass for key configuration
â”‚   â”œâ”€â”€ HARMONICA_KEY_REGISTRY  # Dict mapping key â†’ config
â”‚   â”œâ”€â”€ get_harmonica_config()  # Lookup with validation + aliases
â”‚   â””â”€â”€ get_supported_keys()    # List all available keys

tab_converter/
â””â”€â”€ consts.py                   # MIDI mappings for all 12 keys
    â”œâ”€â”€ C_HARMONICA_MAPPING
    â”œâ”€â”€ G_HARMONICA_MAPPING
    â”œâ”€â”€ BB_HARMONICA_MAPPING
    â”œâ”€â”€ ... (all 12 keys)

image_converter/
â””â”€â”€ consts.py                   # Hole coordinate mappings
    â”œâ”€â”€ C_NEW_MODEL_HOLE_MAPPING
    â”œâ”€â”€ G_MODEL_HOLE_MAPPING
    â”œâ”€â”€ STANDARD_MODEL_HOLE_MAPPING
    â””â”€â”€ ... (aliases for all keys)
```

### **Error Handling**
```bash
# Invalid key shows helpful error
python cli.py create-video song.wav song.txt --key X
# âŒ Error: Unsupported harmonica key: X. Supported keys: A, AB, B, BB, C, CS, D, E, EB, F, FS, G
```

---

## Next Session Tasks - Phase 2 Refactoring (OUTDATED)

### 1. Phase 2 Code Review & Simplification
- **VideoCreator class**: Review for OOP improvements
- **TabMapper/TabMatcher**: Evaluate for refactoring opportunities
- **Animation pipeline**: Optimize performance and readability
- **Error handling**: Add robust error handling throughout Phase 2

### 2. Testing & Validation
- **Unit tests**: Create tests for AudioProcessor, MidiGenerator
- **Integration tests**: End-to-end pipeline testing
- **Performance testing**: Benchmark video generation speed
- **Edge case handling**: Complex videos, missing files, corrupted data

### 3. Code Quality Improvements
- **Type hints**: Add comprehensive type annotations
- **Documentation**: Improve docstrings and inline comments
- **Logging**: Replace print statements with proper logging
- **Configuration**: Externalize hardcoded values

### 4. Commit & Version Control
- **Git commit**: Save all Phase 1 improvements
- **Branch strategy**: Consider feature branches for Phase 2 work
- **Changelog**: Document breaking changes and new features

## Testing Strategy - Bottom-Up Implementation Plan

### ðŸ§ª **Current Status: Phase 3 COMPLETE! âœ… 502/502 Tests Passing**
- âœ… **Phase 1 DONE**: Data models tests (TabEntry, Tabs, NoteEvent) - 17 tests
- âœ… **Phase 2 DONE**: Core business logic - 120 tests
  - âœ… TabMapper (MIDIâ†’Tab conversion) - 24 tests
  - âœ… MidiGenerator (Audioâ†’MIDI pipeline) - 26 tests
  - âœ… AudioProcessor (Audio processing workflow) - 23 tests
  - âœ… TabTextParser (.txt file parsing) - 53 tests âœ¨ All edge cases fixed!
- âœ… **Phase 3 DONE**: Complex Integration & Components - 365 tests
  - âœ… VideoCreator (text-based structure) - 40 tests
  - âœ… AudioExtractor (audio extraction) - 54 tests
  - âœ… Utils (directory management, MIDI) - 33 tests
  - âœ… TabPhraseAnimator - 36 tests
  - âœ… TabMatcher (tab timing alignment) - 28 tests
  - âœ… Animator (animation system) - 39 tests
  - âœ… ColorScheme - 18 tests
  - âœ… Consts - 14 tests
  - âœ… FigureFactory - 29 tests
  - âœ… HarmonicaLayout - 35 tests
  - âœ… VideoProcessor - 33 tests
- ðŸš§ **NEXT: Final Testing Phase** ðŸš§

### ðŸ“ **Test Structure (1:1 Source Mapping)**
```
Source Structure                Test Structure                        Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€
tab_converter/                  tests/tab_converter/
â”œâ”€â”€ models.py          â†’        â”œâ”€â”€ test_models.py                    âœ… DONE (17 tests)
â”œâ”€â”€ tab_mapper.py      â†’        â”œâ”€â”€ test_tab_mapper.py                âœ… DONE (24 tests)
â”œâ”€â”€ consts.py          â†’        â””â”€â”€ conftest.py                       âœ… DONE

harmonica_pipeline/             tests/harmonica_pipeline/
â”œâ”€â”€ video_creator.py   â†’        â”œâ”€â”€ test_video_creator.py             âœ… DONE (40 tests)
â”œâ”€â”€ midi_generator.py  â†’        â”œâ”€â”€ test_midi_generator.py            âœ… DONE (26 tests)
â””â”€â”€ midi_processor.py  â†’        â””â”€â”€ conftest.py                       âœ… DONE

utils/                          tests/utils/
â”œâ”€â”€ audio_extractor.py â†’        â”œâ”€â”€ test_audio_extractor.py           âœ… DONE (54 tests)
â”œâ”€â”€ audio_processor.py â†’        â”œâ”€â”€ test_audio_processor.py           âœ… DONE (23 tests)
â””â”€â”€ utils.py          â†’         â”œâ”€â”€ test_utils.py                     âœ… DONE (33 tests)
                                â””â”€â”€ conftest.py                       âœ… DONE

tab_phrase_animator/            tests/tab_phrase_animator/
â”œâ”€â”€ tab_text_parser.py â†’        â”œâ”€â”€ test_tab_text_parser.py           âœ… DONE (53 tests)
â”œâ”€â”€ tab_phrase_animator.py â†’    â”œâ”€â”€ test_tab_phrase_animator.py       âœ… DONE (36 tests)
â””â”€â”€ tab_matcher.py     â†’        â”œâ”€â”€ test_tab_matcher.py               âœ… DONE (28 tests)
                                â””â”€â”€ conftest.py                       âœ… DONE

image_converter/                tests/image_converter/
â”œâ”€â”€ animator.py        â†’        â”œâ”€â”€ test_animator.py                  âœ… DONE (39 tests)
â”œâ”€â”€ color_scheme.py    â†’        â”œâ”€â”€ test_color_scheme.py              âœ… DONE (18 tests)
â”œâ”€â”€ consts.py          â†’        â”œâ”€â”€ test_consts.py                    âœ… DONE (14 tests)
â”œâ”€â”€ figure_factory.py  â†’        â”œâ”€â”€ test_figure_factory.py            âœ… DONE (29 tests)
â”œâ”€â”€ harmonica_layout.py â†’       â”œâ”€â”€ test_harmonica_layout.py          âœ… DONE (35 tests)
â”œâ”€â”€ video_processor.py â†’        â”œâ”€â”€ test_video_processor.py           âœ… DONE (33 tests)
â””â”€â”€ ...                â†’        â””â”€â”€ conftest.py                       âœ… DONE

./                              tests/
â”œâ”€â”€ cli.py             â†’        â”œâ”€â”€ test_cli.py                       ðŸ“ TODO
â””â”€â”€ ...                â†’        â”œâ”€â”€ conftest.py                       âœ… DONE
                                â””â”€â”€ test_integration.py                ðŸ“ TODO
```

### ðŸŽ¯ **Final Testing Phase - Remaining Work**

#### **Phase 4: Coverage Analysis & CLI Testing (2-3 commits)**
1. **test_cli.py** - Command-line interface testing (generate-midi, create-video commands)
2. **test_integration.py** - End-to-end workflow validation
3. **Coverage analysis** - Run pytest-cov to identify untested code paths
4. **Fill coverage gaps** - Add tests for missed functions/edge cases

#### **Phase 5: Code Quality & Cleanup (2-3 commits)**
5. **TODO review** - Scan codebase for TODO comments, prioritize fixes
6. **Performance testing** - Benchmark critical paths and memory usage
7. **Documentation** - Update docstrings, add inline comments where needed
8. **Type hints** - Ensure comprehensive type annotations

### ðŸš€ **Updated Commit Strategy**
```bash
# Phase 4 - Final Testing:
1. test: Add CLI integration tests (generate-midi, create-video commands)
2. test: Add end-to-end integration test suite
3. test: Achieve 90%+ code coverage with gap-filling tests

# Phase 5 - Quality & Cleanup:
4. fix: Address high-priority TODOs discovered during testing
5. perf: Add performance benchmarking and optimization
6. docs: Update documentation, docstrings, and type hints
7. docs: Create GitHub issues for remaining TODOs
```

### ðŸ“Š **Current Testing Metrics** âœ… COMPLETE!
- **Total Tests**: 562 tests (ALL PASSING âœ…)
- **Coverage**: **99%** (all major components tested)
- **Modules Tested**: 17/17 source modules (cli.py âœ…, midi_processor.py âœ…)
- **Test Files**: 17 test modules across 5 packages
- **Achievement**: 99% coverage achieved! ðŸŽ‰

### âœ… **Completed Testing Phase**
1. âœ… **Coverage analysis** - 99% achieved
2. âœ… **test_cli.py** - 45 tests, 99% coverage
3. âœ… **test_midi_processor.py** - 15 tests, 100% coverage
4. âœ… **TODO review** - Documented in stretch tasks below
5. âœ… **Test isolation fixes** - matplotlib backend + early imports

### ðŸŽ¨ **Conftest Architecture Strategy** âœ…
- **Global fixtures**: Core data structures, common utilities
- **Module fixtures**: Specific to each source module in their conftest.py
- **Hierarchical inheritance**: Module conftest inherits global automatically
- **DRY principle**: Shared fixtures prevent duplication across test files

## ðŸš€ Stretch Tasks / Future Enhancements

### Integration Testing (Optional)
**Priority:** Low
**Status:** Not required - unit/component tests provide 99% coverage

**Potential test_integration.py coverage:**
- End-to-end: Video â†’ MIDI â†’ Fixed MIDI â†’ Final Video
- Full pipeline workflow validation
- Real file I/O with sample data
- Performance benchmarking

**Why it's optional:**
- Current unit tests thoroughly cover all components
- Component integration is tested via existing tests
- Would add ~50+ tests but minimal coverage gain
- Better ROI on feature development vs. integration tests

### Codebase TODOs (Documented)

#### 1. TabMatcher Algorithm Improvements
**Location:** `tab_phrase_animator/tab_matcher.py` (lines 30-35, 150-154, 161)
**Priority:** Medium
**Status:** Experimental feature working, marked for future enhancement

**Current Limitations:**
- Simple first-match strategy
- No timing proximity scoring
- No chord inversion support
- Basic error handling

**Suggested Improvements:**
- Implement timing-proximity scoring algorithm
- Support for different time signatures
- Grace note and ornament handling
- More robust chord matching
- Better error messages with match statistics

**When to implement:** If users report tab matching accuracy issues

#### 2. MIDI Bend Detection
**Location:** `tab_converter/tab_mapper.py` (line 113)
**Priority:** Low
**Status:** Feature request, not critical

**Description:**
Currently, bend notation only supported in `.txt` files. Future enhancement
could detect pitch bends from MIDI pitch bend events and automatically set
`is_bend=True` for bent notes.

**Implementation Notes:**
- Analyze MIDI pitch bend messages
- Correlate with note events
- Infrastructure already exists (`is_bend` field in `TabEntry`)
- Would enhance automation but not essential for workflow

**When to implement:** User feature request or when adding advanced MIDI analysis

#### 3. Performance Optimization
**Priority:** Low
**Status:** Not critical, current performance acceptable

**Potential Optimizations:**
- Video generation speed improvements
- MIDI processing parallelization
- Caching strategies for repeated operations
- Memory usage profiling and optimization

**When to implement:** If users report performance issues with long videos

---

## ðŸŽ¯ NEXT FEATURES - Performance & Auto-Tab Generation

### **Implementation Order (USER REQUESTED):**
1. ðŸ”² **FPS Optimization** - Reduce tab/harmonica FPS to 15 (50% speed/size improvement)
2. ðŸ”² **Cleanup Individual Pages** - Add flag to delete page videos after compositor
3. ðŸ”² **Auto-Tab Generation** - Generate .txt from MIDI automatically (with quick-fix capability)
4. ðŸ”² **Stem Splitting** - Separate harmonica from guitar/background (Demucs, separate command)
5. ðŸ”² **Better MIDI Libraries** - Benchmark alternatives to basic_pitch (experimental)

---

### **Feature 1: FPS Optimization (DO FIRST)**

#### **Goal:**
Reduce rendering time and file sizes by ~50% using lower FPS for tab/harmonica animations.

#### **What to Do:**
1. **Add CLI flags** to `cli.py`:
   ```bash
   python cli.py create-video song.wav song.txt --tabs-fps 15 --harmonica-fps 15
   ```
   - `--tabs-fps`: FPS for tab phrase animations (default: 15, previously hardcoded 30)
   - `--harmonica-fps`: FPS for harmonica animation (default: 15, previously hardcoded 15)

2. **Modify `VideoCreatorConfig`** (`harmonica_pipeline/video_creator_config.py`):
   - Add fields: `tabs_fps: int = 15` and `harmonica_fps: int = 15`
   - Pass to animators

3. **Update `VideoCreator`** (`harmonica_pipeline/video_creator.py`):
   - Pass `config.harmonica_fps` to `animator.create_animation(fps=...)`
   - Pass `config.tabs_fps` to `tab_phrase_animator.create_animations(fps=...)`

4. **Test:**
   - Generate video with default FPS (15)
   - Generate video with `--tabs-fps 30` (backwards compat)
   - Verify 15fps looks good, renders faster

#### **Files to Modify:**
- `cli.py` - Add `--tabs-fps` and `--harmonica-fps` arguments
- `harmonica_pipeline/video_creator_config.py` - Add fps fields
- `harmonica_pipeline/video_creator.py` - Pass fps to animators

#### **Success Criteria:**
âœ… CLI accepts fps flags
âœ… Videos render with specified FPS
âœ… 15fps default saves ~50% time/size
âœ… All tests pass

---

### **Feature 2: Cleanup Individual Pages (DO SECOND)**

#### **Goal:**
Save disk space by optionally deleting individual page videos after full compositor runs.

#### **What to Do:**
1. **Add CLI flag** to `cli.py`:
   ```bash
   python cli.py create-video song.wav song.txt --no-keep-individual-pages
   ```
   - Generates full video, then deletes `page1.mov`, `page2.mov`, etc.
   - Only keeps `MySong_full_tabs.mov`

2. **Modify `VideoCreatorConfig`**:
   - Add field: `keep_individual_pages: bool = True` (default keeps them)

3. **Update `VideoCreator._create_tab_animations()`**:
   - Already has cleanup logic for `--only-full-tab-video` (lines 527-534)
   - Rename/extend to handle `--no-keep-individual-pages`

4. **Test:**
   - Run with flag, verify individual pages deleted
   - Run without flag, verify pages kept
   - Verify full video still correct

#### **Files to Modify:**
- `cli.py` - Add `--no-keep-individual-pages` argument
- `harmonica_pipeline/video_creator_config.py` - Add `keep_individual_pages` field
- `harmonica_pipeline/video_creator.py` - Use existing cleanup logic

#### **Success Criteria:**
âœ… CLI accepts flag
âœ… Individual pages deleted when flag set
âœ… Individual pages kept when flag not set
âœ… Full video unaffected
âœ… All tests pass

---

### **Feature 3: Auto-Tab Generation (DO THIRD)**

#### **Goal:**
Auto-generate tab `.txt` files from MIDI, with easy manual correction workflow.

#### **Workflow:**
```bash
# Option A: Two-step (user can edit .txt between steps)
python cli.py generate-tabs MySong.mid --output MySong.txt
# User edits MySong.txt if needed (QUICK FIXES!)
python cli.py create-video MySong.wav MySong.txt

# Option B: One-shot (auto-generates, saves .txt, uses it)
python cli.py create-video MySong.wav MySong.mid --auto-tabs
# Creates MySong_auto.txt automatically
```

#### **What to Do:**

**Step 1: Create TabTextGenerator class**
1. **New file:** `tab_converter/tab_text_generator.py`
2. **Class:** `TabTextGenerator`
3. **Input:** `List[TabEntry]` (from MIDI)
4. **Output:** Formatted `.txt` string (same format as current .txt files)

**Logic:**
- **Page breaks:** Timing gap >2s = new page
- **Line breaks:** ~8-12 notes per line, max 4-6 lines per page
- **Chord detection:** Notes within 50ms = single chord
- **Format:** Match existing .txt format exactly (backwards compatible)

**Example Output:**
```
Page 1
-45 -4 5 6 -6
6 -5 5 -4 -45'
6 7 -7 7 -8

Page 2
8 -8 8 7 -7
7 6 -6 6 5
```

**Step 2: Add CLI commands**
1. **New command:** `generate-tabs` in `cli.py`
   ```bash
   python cli.py generate-tabs MySong.mid --output MySong.txt
   ```
2. **New flag:** `--auto-tabs` to `create-video` command
   ```bash
   python cli.py create-video MySong.wav MySong.mid --auto-tabs
   ```

**Step 3: Integration**
- `generate-tabs` command:
  1. Load MIDI â†’ `MidiProcessor.load_note_events()`
  2. Convert to tabs â†’ `TabMapper.note_events_to_tabs()`
  3. Generate text â†’ `TabTextGenerator.generate(tabs)`
  4. Save to file

- `create-video --auto-tabs`:
  1. Generate .txt file (as above)
  2. Use existing flow with generated .txt

**Step 4: Testing**
- Generate .txt from various MIDIs
- Verify format matches existing .txt parser
- Test quick fixes (edit .txt, regenerate video)
- Ensure backwards compatibility

#### **Files to Create/Modify:**
- **NEW:** `tab_converter/tab_text_generator.py` - TabTextGenerator class
- **NEW:** `tests/tab_converter/test_tab_text_generator.py` - Tests
- **MODIFY:** `cli.py` - Add `generate-tabs` command and `--auto-tabs` flag
- **MODIFY:** `harmonica_pipeline/video_creator.py` - Handle MIDI input with auto-tabs

#### **Success Criteria:**
âœ… `generate-tabs` command works
âœ… Generated .txt matches existing format
âœ… `--auto-tabs` flag creates video from MIDI
âœ… User can edit .txt for quick fixes
âœ… Existing .txt workflow unchanged
âœ… All tests pass

---

### **Quick Reference for Claude:**

**When user says "implement the next planned feature":**
1. Check which features are marked ðŸ”² (not done)
2. Implement in order: FPS â†’ Cleanup â†’ Auto-tabs
3. Follow the "What to Do" steps precisely
4. Mark feature âœ… when complete
5. Run tests, commit

**When user says "I want to fix tab mistakes quickly":**
- This is the **auto-tabs feature (#3)**
- Solution: Generate .txt file, user edits it, re-run video creation
- Easy workflow: `generate-tabs â†’ edit .txt â†’ create-video`

---

### **Feature 4: Stem Splitting - Separate Harmonica from Background (DO FOURTH)**

#### **Goal:**
Isolate harmonica audio from guitar/background instruments using AI source separation for cleaner MIDI generation.

#### **Library: Demucs (Meta AI)**
- State-of-the-art audio source separation
- Splits into: vocals, drums, bass, other
- Harmonica typically in "vocals" or "other" stem
- Quality over speed (OK for <1min recordings)

#### **Workflow:**
```bash
# Step 1: Split stems (separate command)
python cli.py split-stems MySong.mp4 --output stems/
# Creates: stems/vocals.wav, stems/drums.wav, stems/bass.wav, stems/other.wav
# User sees: "âœ… Created 4 stems in stems/ - listen and pick best one"

# Step 2: User manually listens to each stem, picks best (e.g., vocals.wav)

# Step 3: Generate MIDI from chosen stem
python cli.py generate-midi stems/vocals.wav
# Rest of workflow unchanged
```

#### **What to Do:**

**Step 1: Install and test Demucs**
1. Add dependency: `demucs` to `pyproject.toml`
2. Test on sample harmonica+guitar recording
3. Verify output quality manually

**Step 2: Create StemSplitter class**
1. **New file:** `utils/stem_splitter.py`
2. **Class:** `StemSplitter`
3. **Input:** Audio/video file path
4. **Output:** 4 WAV files (vocals, drums, bass, other)

**Core logic:**
```python
import demucs.api

class StemSplitter:
    def split(self, input_path: str, output_dir: str) -> dict:
        # Extract audio if video
        # Run Demucs separation
        # Save 4 stems to output_dir
        # Return dict: {"vocals": "path", "drums": "path", ...}
```

**Step 3: Add CLI command**
1. New command: `split-stems` in `cli.py`
   ```bash
   python cli.py split-stems MySong.mp4 --output stems/
   ```
2. Arguments:
   - `input`: Video/audio file
   - `--output`: Output directory (default: `stems/`)
   - Optional: `--model htdemucs` (Demucs model variant)

**Step 4: Integration**
- Works as standalone command (NOT integrated into generate-midi)
- User workflow: `split-stems â†’ listen â†’ pick best â†’ generate-midi`
- Clear user guidance printed after splitting

**Step 5: Testing**
1. Manual test: harmonica+guitar recording
2. Verify all 4 stems created correctly
3. Check processing time (<1min for 30s audio)
4. Quality check: is harmonica isolated?

#### **Files to Create/Modify:**
- **NEW:** `utils/stem_splitter.py` - StemSplitter class
- **NEW:** `tests/utils/test_stem_splitter.py` - Tests
- **MODIFY:** `cli.py` - Add `split-stems` command
- **MODIFY:** `pyproject.toml` - Add demucs dependency

#### **Success Criteria:**
âœ… `split-stems` command works
âœ… Creates 4 clean WAV files
âœ… Processing time reasonable (<2min for 1min audio)
âœ… Harmonica isolated from guitar in output stems
âœ… Clear user instructions printed
âœ… Tests passing

#### **Example Output:**
```
ðŸŽµ Splitting stems from MySong.mp4...
â±ï¸  Processing with Demucs (this may take 30-60 seconds)...
âœ… Created 4 stems in stems/:
   - vocals.wav (likely has harmonica)
   - drums.wav
   - bass.wav
   - other.wav

ðŸ‘‚ Listen to each stem and pick the best one
ðŸ’¡ Then run: python cli.py generate-midi stems/vocals.wav
```

---

### **Feature 5: Better MIDI Libraries - Benchmark Alternatives (DO FIFTH)**

#### **Goal:**
Research and benchmark alternative audio-to-MIDI libraries to potentially improve note accuracy vs basic_pitch.

#### **Status:** Experimental - may not yield improvement

#### **Libraries to Test:**
1. **Magenta mt3** (Google) - Multi-track transcription, state-of-the-art
2. **crepe** - Monophonic pitch tracking (good for single instruments)
3. **pyin** - Probabilistic YIN algorithm (lightweight)

#### **What to Do:**

**Step 1: Create benchmark framework**
1. **New file:** `tests/experiments/benchmark_midi_libraries.py`
2. Prepare 3-5 test audio files with known ground truth tabs
3. Run all libraries on same samples
4. Compare outputs to ground truth

**Metrics:**
- Note accuracy (precision/recall vs ground truth)
- Timing precision (how close to actual note timing)
- False positive rate
- Processing time

**Step 2: Test each library**
```python
# Benchmark script structure
def test_library(library_name, audio_path, ground_truth_tabs):
    # Run library
    midi_output = library.transcribe(audio_path)

    # Compare to ground truth
    precision = calculate_precision(midi_output, ground_truth_tabs)
    recall = calculate_recall(midi_output, ground_truth_tabs)

    # Return metrics
    return {
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "processing_time": time
    }
```

**Step 3: Analyze results**
- Create comparison table
- If any library shows >10% improvement: implement it
- If no clear winner: stick with basic_pitch

**Step 4: Implementation (only if better library found)**
- Add new library to MidiGenerator as option
- CLI flag: `--midi-engine [basic_pitch|mt3|crepe]`
- Default stays basic_pitch

#### **Files to Create:**
- **NEW:** `tests/experiments/benchmark_midi_libraries.py`
- **NEW:** `tests/experiments/test_samples/` - Ground truth audio + tabs
- **MODIFY:** `harmonica_pipeline/midi_generator.py` (only if better library found)

#### **Success Criteria:**
âœ… Benchmark framework runs on all libraries
âœ… Clear metrics comparison table generated
âœ… Decision made: switch library or keep basic_pitch
âœ… If switch: new library integrated with tests passing

#### **Decision Point:**
- **If no library >10% better:** Document findings, keep basic_pitch
- **If library significantly better:** Implement as new default or optional flag

---

### **Quick Reference for Claude:**

**When user says "implement the next planned feature":**
1. Check which features are marked ðŸ”² (not done)
2. Implement in order: FPS â†’ Cleanup â†’ Auto-tabs â†’ Stem-split â†’ MIDI-benchmark
3. Follow the "What to Do" steps precisely
4. Mark feature âœ… when complete
5. Run tests, commit
